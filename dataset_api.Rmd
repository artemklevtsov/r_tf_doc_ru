---
title: "dataset_api"
output: html_document
---

```{r, echo=FALSE}
# knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
reticulate::use_condaenv("r-reticulate")
```

```{r, echo=FALSE, message=FALSE}
# fix https://github.com/rstudio/keras/issues/930
reticulate::py_config() 
```


# Перевод https://tensorflow.rstudio.com/tools/tfdatasets/articles/introduction.html

API TensorFlow Dataset обеспечивает возможности создания масштабируемых пайплайнов для передачи данных в модели TensorFlow, в том числе:

* чтение данных из различных форматов, включая CSV и TFRecords (стандартный бинарный формат входных данных для TensorFlow);

* преобразования наборов данных, включая применение к ним произвольных функций;

* перемешивание наборов данных, разбивка на батчи и повторение набора по числу эпох;

* интерфейс потоковой передачи для чтения сколь угодно больших наборов данных;

* чтение и преобразование данных являются операциями в составе вычислительного графа TensorFlow, поэтому выполняются кодом на С++ параллельно с обучением модели.

R-интерфейс к TensorFlow Datasets предоставляет доступ к API, включая высокоуровневые функции для удобной интеграции с R-пакетом [keras](https://tensorflow.rstudio.com/keras/) (а также [tfestimators](https://tensorflow.rstudio.com/tfestimators/), документация по которому на момент создания перевода удалена с официального сайта - *прим. пер.*).


## Установка

Для использования `tfdatasets` нужно установить библиотеку TensorFlow и соответствующий R-пакет.

Сперва установите `tfdatasets` с GitHub:

```{r, eval=FALSE}
# devtools::install_github("rstudio/tfdatasets")
remotes::install_github("rstudio/tfdatasets")
```

Затем используйте функцию `install_tensorflow()` для установки TensorFlow:

```{r, eval=FALSE}
library(tfdatasets)
install_tensorflow()
```

Не забывайте перед использованием R-пакета `tensorflow` указать, куда установлена Python-овская библиотека, например, `reticulate::use_condaenv("r-reticulate")` - *прим. пер.*


## Создание набора данных

Наборы данных создаются из текстовых файлов, файлов в формате [tfrecords](https://www.tensorflow.org/api_docs/python/tf/io) или из данных в ОЗУ при помощи [соответствующих функций](https://tensorflow.rstudio.com/tools/tfdatasets/reference/#section-creating-datasets).

### Текстовые файлы

Например, для создания набора данных из текстового файла сперва нужно создать спецификацию того, как записи будут декодироваться при чтении из файла, а затем вызвать `text_line_dataset()` с именем файла и спецификацией:

```{r}
library(tfdatasets)

# создание спецификации для парсинга файла
iris_spec <- csv_record_spec("iris.csv")

# чтение набора данных
dataset <- text_line_dataset("iris.csv", record_spec = iris_spec) 

# структура полученного набора данных
str(dataset)
```

В этом примере функция `csv_record_spec()` обрабатывает файл с образцом данных, который используется для автоматического определения имен и типов столбцов (для этого читается до 1000 первый строк в файле). Вы также можете явно задать имена и/или типы данных для столбцов при помощи параметров `names` и `types` (обратите внимание, что файл-образец при этом не нужен):

```{r}
# задаем имена и типы данных
iris_spec <- csv_record_spec(
  names = c("SepalLength", "SepalWidth", "PetalLength", "PetalWidth", 
            "Species"),
  types = c("double", "double", "double", "double", 
            "integer"), 
  skip = 1
)

# чтение набора данных
dataset <- text_line_dataset("iris.csv", record_spec = iris_spec)
```

Отметим, что мы также указали `skip = 1`, чтобы пропустить первую строку в файле, содержащую имена столбцов.

Поддерживаемые типы: целое число (integer), число с плавающей точкой (double) и строка (character). Вы также можете указывать типы в более компактной форме посредством односимвольных аббревиатур (например, `types = "dddi"`):

```{r}
mtcars_spec <- csv_record_spec("mtcars.csv", types = "dididddiiii")
```


#### Параллельный парсинг